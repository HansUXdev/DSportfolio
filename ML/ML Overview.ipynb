{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c4cc757",
   "metadata": {},
   "source": [
    "| Method                      | Description                                                                                                             | When to Use                                                                 | When Not to Use                                                   | Pros/Cons                                                                                                                            | Works Well With               | Does Not Work Well With      |\n",
    "|-----------------------------|-------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------|--------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------|-------------------------------|-------------------------------|\n",
    "| Linear Regression           | Uses linear relationships between variables to make predictions.                                                        | When underlying relationships are assumed to be linear.                    | When relationships are non-linear or complex.                      | Pros: Simple and interpretable. Cons: Limited to linear relationships.                                                               | Stocks, Bonds                 | Cryptocurrencies              |\n",
    "| Decision Trees              | Models decisions based on a tree-like graph, useful for classification and regression tasks.                            | When dealing with complex decision-making processes.                        | When overfitting is a concern or when interpretability is crucial. | Pros: Easy to understand and interpret. Cons: Prone to overfitting.                                                                  | Credit Risk, Fraud Detection  | High Frequency Trading        |\n",
    "| Random Forest               | Ensemble learning method that constructs multiple decision trees and merges their predictions.                          | When seeking improved prediction accuracy over a single decision tree.      | When model interpretability is essential.                         | Pros: Reduces overfitting, handles non-linear relationships well. Cons: Less interpretable than individual decision trees.             | Portfolio Management          | Algorithmic Trading           |\n",
    "| Gradient Boosting           | Builds models sequentially, each correcting errors from the previous one, usually using decision trees as base learners. | When high predictive accuracy is desired and interpretability is not crucial. | When computational resources are limited or speed is critical.     | Pros: Often achieves high predictive accuracy. Cons: Can be computationally expensive.                                               | Market Trend Analysis         | Real-time Trading             |\n",
    "| Support Vector Machines (SVM) | Constructs hyperplanes in a high-dimensional space to separate classes, effective for classification tasks.              | When dealing with high-dimensional data or non-linear classification.        | When interpretability or computational efficiency is crucial.      | Pros: Effective in high-dimensional spaces. Cons: Less interpretable, sensitive to choice of kernel.                                   | Image Recognition, Genomics   | Large Text Datasets           |\n",
    "| Neural Networks             | Models inspired by the human brain's structure, composed of layers of interconnected nodes.                             | When dealing with large, complex datasets and tasks such as image recognition or natural language processing. | When computational resources are limited or interpretability is crucial. | Pros: Can learn complex relationships. Cons: Require large datasets, computationally expensive, black-box nature.                      | Deep Learning Applications    | Small Datasets                |\n",
    "| Long Short-Term Memory (LSTM) | A type of recurrent neural network (RNN) designed to capture long-term dependencies in sequential data.                  | When studying time-series data with long-term dependencies.                  | When interpretability is more important than predictive power.     | Pros: Effective for time-series prediction, captures long-term dependencies. Cons: Can be prone to overfitting, computationally intensive. | Financial Time Series         | Non-sequential Data           |\n",
    "| Reinforcement Learning       | Learns to make decisions by interacting with an environment, often used in algorithmic trading.                          | When studying dynamic systems with sequential decision-making.               | When interpretability and stability are paramount.                 | Pros: Adaptable to changing environments, learns complex strategies. Cons: Requires significant computational resources, prone to instability. | Game Playing, Robotics        | Static Decision Problems      |\n",
    "| K-Nearest Neighbors         | Classifies data points based on the majority class of their k-nearest neighbors.                                         | When dealing with classification tasks and have labeled data.                | When dealing with high-dimensional data or large datasets.         | Pros: Simple and easy to understand. Cons: Can be computationally expensive with large datasets.                                     | Small to Medium Datasets      | Very Large Datasets           |\n",
    "| Principal Component Analysis (PCA) | Reduces the dimensionality of data while preserving the most important features.                                       | When dealing with high-dimensional data or exploring relationships between variables. | When interpretability of features is crucial.                      | Pros: Reduces dimensionality, maintains most important features. Cons: May lose some information, difficult to interpret transformed features. | Feature Reduction             | Time-Series Analysis          |\n",
    "| Autoencoders                | Neural network models trained to encode and decode input data, useful for feature learning and dimensionality reduction. | When exploring latent representations or reducing dimensionality.            | When interpretability of learned features is essential.           | Pros: Learn complex representations, useful for unsupervised learning tasks. Cons: Black-box nature, challenging to interpret learned features. | Data Compression, Denoising   | Simple Classification Tasks   |\n",
    "| Bayesian Methods            | Incorporates prior beliefs and updates them based on observed data using Bayes' theorem.                                 | When incorporating domain knowledge or dealing with limited data.            | When computational resources are limited or prior beliefs are not well-defined. | Pros: Incorporates uncertainty, can update beliefs with new evidence. Cons: Computationally intensive, requires well-defined priors.      | Risk Assessment               | Large-Scale Machine Learning  |\n",
    "| Gaussian Processes          | Non-parametric Bayesian models that define a distribution over functions, useful for regression tasks.                   | When dealing with small datasets or when uncertainty estimation is crucial.  | When computational resources are limited or data is high-dimensional. | Pros: Flexible, provides uncertainty estimates. Cons: Computationally intensive, scales poorly with large datasets.                  | Small Data Regressions        | Large Datasets                |\n",
    "| Factor Analysis             | Statistical method used to identify underlying factors driving observed data patterns, useful for portfolio construction. | When seeking to understand common underlying factors influencing asset returns. | When data does not exhibit factor structure or when interpretability is paramount. | Pros: Identifies latent factors, aids in portfolio diversification. Cons: Assumes linear relationships, sensitive to model assumptions. | Asset Pricing Models          | High Frequency Data           |\n",
    "| Markov Chain Monte Carlo (MCMC) | Simulation technique for estimating complex probability distributions by generating samples from them.                   | When dealing with complex probabilistic models or estimating parameters in Bayesian inference. | When computational resources are limited or simpler methods suffice. | Pros: Provides approximate posterior distributions, applicable to a wide range of models. Cons: Computationally intensive, convergence may be slow. | Bayesian Inference            | Real-time Analysis            |\n",
    "| Survival Analysis           | Analyzes time-to-event data, useful for studying the duration until an event of interest occurs.                        | When studying event occurrence over time, such as bankruptcy or default.      | When event data is not available or when other methods are more suitable. | Pros: Deals with censored data, handles time-to-event relationships. Cons: Assumes independence of censoring, may require specialized models. | Healthcare, Finance           | Broad Market Indices          |\n",
    "| Markov Decision Processes (MDP) | Models decision-making processes in stochastic environments with discrete time steps.                                   | When modeling sequential decision-making problems with uncertainty.          | When computational resources are limited or when simpler models suffice. | Pros: Captures sequential decision-making, handles uncertainty. Cons: Can be computationally intensive, requires careful modeling of states and transitions. | Decision Analysis             | Non-stochastic Processes      |\n",
    "| Recurrent Neural Networks (RNN) | Neural network models designed to process sequential data, useful for time-series analysis.                             | When studying time-series data with temporal dependencies.                   | When interpretability or computational efficiency is crucial.      | Pros: Captures temporal dependencies, suitable for sequential data. Cons: May suffer from vanishing/exploding gradients, computationally intensive. | Speech Recognition            | Static Image Recognition      |\n",
    "| Ensemble Methods            | Combines multiple models to improve prediction accuracy or stability, examples include bagging and stacking.            | When seeking improved generalization or robustness over individual models.   | When computational resources are limited or when interpretability is crucial. | Pros: Reduces overfitting, improves prediction accuracy. Cons: May increase complexity, requires tuning of ensemble parameters.        | Various Predictive Tasks      | Single Model Tasks            |\n",
    "| Expectation-Maximization (EM) Algorithm | Iterative method for finding maximum likelihood or maximum a posteriori estimates in probabilistic models.             | When dealing with incomplete or missing data, or when fitting latent variable models. | When model assumptions are violated or when simpler methods suffice. | Pros: Handles missing data, useful for fitting complex probabilistic models. Cons: Sensitive to initialization, may converge to local optima. | Mixture Models, Clustering     | Large-Scale Datasets          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3391e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cce618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fe6add",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b89b7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
