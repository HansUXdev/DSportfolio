{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4e62c4-b0b0-419c-8282-a97915d2b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yfinance py_vollib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b0a953-3258-46cc-8c0d-a090e008cf3a",
   "metadata": {},
   "source": [
    "# Data Retrieval: \n",
    "Fetch historical data for SPY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c0dc870-e2f7-40f1-8ef4-6c52b25da1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "62822652-a7c8-41be-8034-758aa550c71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "                  Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2024-02-13  494.529999  497.089996  490.720001  494.079987  494.079987   \n",
      "2024-02-14  496.790009  499.070007  494.399994  498.570007  498.570007   \n",
      "2024-02-15  499.290009  502.200012  498.799988  502.010010  502.010010   \n",
      "2024-02-16  501.700012  502.869995  498.750000  499.510010  499.510010   \n",
      "2024-02-20  497.720001  498.410004  494.459991  496.760010  496.760010   \n",
      "\n",
      "               Volume  Bollinger_High  Bollinger_Low      MACD    Signal  ...  \\\n",
      "Date                                                                      ...   \n",
      "2024-02-13  113099200      504.900087     473.914919  6.587714  6.426473  ...   \n",
      "2024-02-14   68387800      504.459707     476.983298  6.468158  6.434810  ...   \n",
      "2024-02-15   61683000      504.884360     479.110647  6.575193  6.462887  ...   \n",
      "2024-02-16   75461200      505.325914     480.377095  6.384692  6.447248  ...   \n",
      "2024-02-20   71486678      505.279409     481.754600  5.943305  6.346459  ...   \n",
      "\n",
      "                    R1          S1          R2          S2          R3  \\\n",
      "Date                                                                     \n",
      "2024-02-13  497.264984  490.894989  500.362488  487.622498  503.634979   \n",
      "2024-02-14  500.905014  496.235001  502.322517  492.982491  505.575027   \n",
      "2024-02-15  503.710022  500.309998  504.655029  497.854980  507.110046   \n",
      "2024-02-16  501.570007  497.450012  504.279999  496.040009  505.690002   \n",
      "2024-02-20  498.735016  494.785004  500.547516  492.647491  502.685028   \n",
      "\n",
      "                    S3          R4          S4           OBV       ATR  \n",
      "Date                                                                    \n",
      "2024-02-13  484.524994  513.102478  474.882507 -2.166675e+09  4.411427  \n",
      "2024-02-14  491.564987  511.662544  483.642464 -2.098287e+09  4.559287  \n",
      "2024-02-15  496.909973  511.455078  491.054932 -2.036604e+09  4.634288  \n",
      "2024-02-16  493.330017  512.519989  487.800018 -2.112065e+09  4.625002  \n",
      "2024-02-20  490.834991  508.447540  484.747467 -2.183552e+09  4.877860  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "def fetch_and_process_data(_asset):\n",
    "    # Fetch data for the specified asset\n",
    "    hist = yf.download(_asset, start='2022-01-01')\n",
    "\n",
    "    # Indicator calculations as defined earlier\n",
    "    def bollinger_bands(data, window=20, num_std=2):\n",
    "        rolling_mean = data['Close'].rolling(window=window).mean()\n",
    "        rolling_std = data['Close'].rolling(window=window).std()\n",
    "        data['Bollinger_High'] = rolling_mean + (rolling_std * num_std)\n",
    "        data['Bollinger_Low'] = rolling_mean - (rolling_std * num_std)\n",
    "        return data\n",
    "\n",
    "    def macd(data, short_window=12, long_window=26, signal_window=9):\n",
    "        short_ema = data['Close'].ewm(span=short_window, adjust=False).mean()\n",
    "        long_ema = data['Close'].ewm(span=long_window, adjust=False).mean()\n",
    "        data['MACD'] = short_ema - long_ema\n",
    "        data['Signal'] = data['MACD'].ewm(span=signal_window, adjust=False).mean()\n",
    "        return data\n",
    "\n",
    "    def rsi(data, periods=14, ema=True):\n",
    "        close_delta = data['Close'].diff()\n",
    "        up = close_delta.clip(lower=0)\n",
    "        down = -1 * close_delta.clip(upper=0)\n",
    "        \n",
    "        if ema:\n",
    "            ma_up = up.ewm(com=periods - 1, adjust=True, min_periods=periods).mean()\n",
    "            ma_down = down.ewm(com=periods - 1, adjust=True, min_periods=periods).mean()\n",
    "        else:\n",
    "            ma_up = up.rolling(window=periods, adjust=False).mean()\n",
    "            ma_down = down.rolling(window=periods, adjust=False).mean()\n",
    "        \n",
    "        rsi = ma_up / ma_down\n",
    "        data['RSI'] = 100 - (100 / (1 + rsi))\n",
    "        return data\n",
    "        \n",
    "    def obv(data):\n",
    "        \"\"\"Calculate On-Balance Volume.\"\"\"\n",
    "        obv = (np.sign(data['Close'].diff()) * data['Volume']).fillna(0).cumsum()\n",
    "        data['OBV'] = obv\n",
    "        return data\n",
    "\n",
    "    def atr(data, window=14):\n",
    "        \"\"\"Calculate Average True Range (ATR).\"\"\"\n",
    "        high_low = data['High'] - data['Low']\n",
    "        high_close = np.abs(data['High'] - data['Close'].shift())\n",
    "        low_close = np.abs(data['Low'] - data['Close'].shift())\n",
    "        ranges = pd.concat([high_low, high_close, low_close], axis=1)\n",
    "        true_range = np.max(ranges, axis=1)\n",
    "        data['ATR'] = true_range.rolling(window=window).mean()\n",
    "        return data\n",
    "\n",
    "    def woodie_pivots(data):\n",
    "        # Calculate Woodie's pivot points\n",
    "        data['Pivot'] = (data['High'] + data['Low'] + 2 * data['Close']) / 4\n",
    "        data['R1'] = 2 * data['Pivot'] - data['Low']\n",
    "        data['S1'] = 2 * data['Pivot'] - data['High']\n",
    "        data['R2'] = data['Pivot'] + (data['High'] - data['Low'])\n",
    "        data['S2'] = data['Pivot'] - (data['High'] - data['Low'])\n",
    "        data['R3'] = data['High'] + 2 * (data['Pivot'] - data['Low'])\n",
    "        data['S3'] = data['Low'] - 2 * (data['High'] - data['Pivot'])\n",
    "        data['R4'] = data['Pivot'] + 3 * (data['High'] - data['Low'])\n",
    "        data['S4'] = data['Pivot'] - 3 * (data['High'] - data['Low'])\n",
    "        return data\n",
    "\n",
    "    # Apply each indicator function to the data\n",
    "    hist = bollinger_bands(hist)\n",
    "    hist = macd(hist)\n",
    "    hist = rsi(hist)\n",
    "    hist = woodie_pivots(hist)\n",
    "    hist = obv(hist)\n",
    "    hist = atr(hist)\n",
    "    # Repeat for other indicators as necessary...\n",
    "\n",
    "    # Note: No explicit parallel processing applied here due to sequential dependency of calculations on data.\n",
    "\n",
    "    # Ensure all NaN values created by indicators are handled appropriately\n",
    "    hist.dropna(inplace=True)\n",
    "\n",
    "    return hist\n",
    "\n",
    "# Example usage\n",
    "spy_data = fetch_and_process_data(\"SPY\")\n",
    "print(spy_data.tail())  # Display the last few rows to verify the outcome\n",
    "# spy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a317cb-74c2-4051-acd3-e440099b697b",
   "metadata": {},
   "source": [
    "# Check Data For any errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f88c841-241b-4541-8c68-48b555fa63a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Issue: Data might be missing trading days: 2022-04-15, 2023-04-07\n"
     ]
    }
   ],
   "source": [
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "\n",
    "def check_data_errors(data):\n",
    "    errors = []\n",
    "\n",
    "    # Check for missing values\n",
    "    if data.isnull().values.any():\n",
    "        errors.append(\"Issue: Data contains missing values.\")\n",
    "    \n",
    "    # Check for duplicate dates\n",
    "    if data.index.duplicated().any():\n",
    "        errors.append(\"Issue: Data contains duplicate dates.\")\n",
    "    \n",
    "    # Outliers in price data\n",
    "    z_scores = np.abs((data['Close'] - data['Close'].mean()) / data['Close'].std())\n",
    "    if z_scores[z_scores > 3].any():\n",
    "        errors.append(\"Issue: Data contains potential outliers in 'Close' prices.\")\n",
    "    \n",
    "    # Volume checks\n",
    "    if (data['Volume'] == 0).any():\n",
    "        errors.append(\"Issue: Data contains days with zero volume.\")\n",
    "    if ((data['Volume'].diff() / data['Volume']).abs() > 5).any():\n",
    "        errors.append(\"Issue: Data contains unexpected spikes in volume.\")\n",
    "    \n",
    "    # Continuity of dates, excluding weekends and public holidays\n",
    "    cal = USFederalHolidayCalendar()\n",
    "    holidays = cal.holidays(start=data.index.min(), end=data.index.max())\n",
    "    business_days = pd.date_range(start=data.index.min(), end=data.index.max(), freq='B')\n",
    "    business_days = business_days[~business_days.isin(holidays)]  # Exclude holidays\n",
    "    \n",
    "    missing_dates = business_days.difference(data.index).tolist()\n",
    "    if missing_dates:\n",
    "        formatted_dates = ', '.join([d.strftime('%Y-%m-%d') for d in missing_dates])\n",
    "        errors.append(f\"Issue: Data might be missing trading days: {formatted_dates}\")\n",
    "\n",
    "    return errors\n",
    "\n",
    "# Example usage\n",
    "spy_data = fetch_and_process_data(\"SPY\")  # Assuming this function returns data with DateTimeIndex\n",
    "errors = check_data_errors(spy_data)\n",
    "if errors:\n",
    "    for error in errors:\n",
    "        print(error)\n",
    "else:\n",
    "    print(\"No issues detected in the data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2af43f-ca6f-4646-b422-1527be7078fb",
   "metadata": {},
   "source": [
    "The error message indicating missing trading days for specific dates such as April 19, 2019, April 10, 2020, April 2, 2021, April 15, 2022, and April 7, 2023, highlights dates that are actually Good Friday. In the United States, the stock market (NYSE, NASDAQ) is closed on Good Friday, which is not a federal holiday and therefore not included in the USFederalHolidayCalendar. This explains why these dates were flagged as missing trading days by the previous function.\n",
    "\n",
    "To address this and accurately reflect the trading calendar, we need to manually account for Good Friday and potentially other market-specific closures not covered by the federal holiday calendar. Here's an updated version of the function that checks for missing trading days, now including an adjustment for Good Friday and a more general approach to handling non-trading days:\n",
    "\n",
    "Frankly, this is good enough for "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396bdc30-a5c0-4fb9-b5f6-96c385ddf4e0",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "681825dd-d5ee-44c3-985a-a6a1cbd2ee83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature Close (0.1713)\n",
      "2. feature Pivot (0.1344)\n",
      "3. feature S1 (0.1285)\n",
      "4. feature Low (0.1182)\n",
      "5. feature S2 (0.1163)\n",
      "6. feature R1 (0.0996)\n",
      "7. feature S3 (0.0806)\n",
      "8. feature High (0.0465)\n",
      "9. feature R2 (0.0321)\n",
      "10. feature Open (0.0234)\n",
      "11. feature R3 (0.0223)\n",
      "12. feature Bollinger_Low (0.0092)\n",
      "13. feature S4 (0.0067)\n",
      "14. feature Bollinger_High (0.0019)\n",
      "15. feature MACD (0.0017)\n",
      "16. feature Signal (0.0014)\n",
      "17. feature Volume (0.0013)\n",
      "18. feature ATR (0.0013)\n",
      "19. feature RSI (0.0012)\n",
      "20. feature OBV (0.0012)\n",
      "21. feature R4 (0.0009)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure 'spy_data' is a DataFrame loaded with required data\n",
    "# Assuming spy_data is already defined and contains the necessary columns\n",
    "\n",
    "# Define the column names\n",
    "columns = ['Open', 'High', 'Low', 'Close', 'Volume', 'Bollinger_High', 'Bollinger_Low', 'MACD', 'Signal', 'RSI', \n",
    "           'Pivot', 'R1', 'S1', 'R2', 'S2', 'R3', 'S3', 'R4', 'S4', 'OBV', 'ATR']\n",
    "\n",
    "# Check if all columns are in the DataFrame, otherwise print a warning\n",
    "missing_columns = [col for col in columns if col not in spy_data.columns]\n",
    "if missing_columns:\n",
    "    print(f\"Warning: Missing columns {missing_columns} in the DataFrame. Please ensure all indicators are calculated before this step.\")\n",
    "else:\n",
    "    # Select features and target, including the new indicators\n",
    "    features = spy_data[columns]\n",
    "\n",
    "    # Shift the 'Close' column to the next day for prediction\n",
    "    target = spy_data['Close'].shift(-1)\n",
    "\n",
    "    # Drop the last row from features and target to remove the NaN values from shifting\n",
    "    features = features.iloc[:-1]\n",
    "    target = target.iloc[:-1]\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Get feature importances\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "    for f in range(X_train.shape[1]):\n",
    "        print(f\"{f + 1}. feature {X_train.columns[indices[f]]} ({importances[indices[f]]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca34802-d4e3-4a87-b1b1-a8ba5944bec3",
   "metadata": {},
   "source": [
    "# Credit Spread Pricing\n",
    "Here we want to use R1-4 and S1-S4 to find the nearest 50 cent spread.\n",
    "We'll then try to determine the probablity of each expiring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "40ddc341-66b2-44c7-a8ae-ac7565e4e2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           R1-R2 Put Spread R1-R3 Put Spread R1-R4 Put Spread  \\\n",
      "Date                                                            \n",
      "2022-01-31   (455.0, 458.0)   (455.0, 465.5)   (455.0, 479.0)   \n",
      "2022-02-01   (456.5, 458.5)   (456.5, 463.0)   (456.5, 471.5)   \n",
      "2022-02-02   (460.0, 461.5)   (460.0, 465.0)   (460.0, 471.5)   \n",
      "2022-02-03   (450.0, 455.0)   (450.0, 457.5)   (450.0, 470.0)   \n",
      "2022-02-04   (453.0, 457.5)   (453.0, 462.0)   (453.0, 475.5)   \n",
      "...                     ...              ...              ...   \n",
      "2024-02-13   (497.5, 500.5)   (497.5, 503.5)   (497.5, 513.0)   \n",
      "2024-02-14   (501.0, 502.5)   (501.0, 505.5)   (501.0, 511.5)   \n",
      "2024-02-15   (503.5, 504.5)   (503.5, 507.0)   (503.5, 511.5)   \n",
      "2024-02-16   (501.5, 504.5)   (501.5, 505.5)   (501.5, 512.5)   \n",
      "2024-02-20   (498.5, 500.5)   (498.5, 502.5)   (498.5, 508.5)   \n",
      "\n",
      "           S1-S2 Call Spread S1-S3 Call Spread S1-S4 Call Spread  \n",
      "Date                                                              \n",
      "2022-01-31    (444.5, 437.0)    (444.5, 434.0)    (444.5, 416.0)  \n",
      "2022-02-01    (449.5, 445.0)    (449.5, 443.0)    (449.5, 431.5)  \n",
      "2022-02-02    (455.0, 451.5)    (455.0, 449.5)    (455.0, 441.5)  \n",
      "2022-02-03    (443.0, 440.5)    (443.0, 435.5)    (443.0, 426.0)  \n",
      "2022-02-04    (444.0, 439.5)    (444.0, 435.5)    (444.0, 421.5)  \n",
      "...                      ...               ...               ...  \n",
      "2024-02-13    (491.0, 487.5)    (491.0, 484.5)    (491.0, 475.0)  \n",
      "2024-02-14    (496.0, 493.0)    (496.0, 491.5)    (496.0, 483.5)  \n",
      "2024-02-15    (500.5, 498.0)    (500.5, 497.0)    (500.5, 491.0)  \n",
      "2024-02-16    (497.5, 496.0)    (497.5, 493.5)    (497.5, 488.0)  \n",
      "2024-02-20    (495.0, 492.5)    (495.0, 491.0)    (495.0, 484.5)  \n",
      "\n",
      "[516 rows x 6 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R1-R2 Put Spread</th>\n",
       "      <th>R1-R3 Put Spread</th>\n",
       "      <th>R1-R4 Put Spread</th>\n",
       "      <th>S1-S2 Call Spread</th>\n",
       "      <th>S1-S3 Call Spread</th>\n",
       "      <th>S1-S4 Call Spread</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-31</th>\n",
       "      <td>(455.0, 458.0)</td>\n",
       "      <td>(455.0, 465.5)</td>\n",
       "      <td>(455.0, 479.0)</td>\n",
       "      <td>(444.5, 437.0)</td>\n",
       "      <td>(444.5, 434.0)</td>\n",
       "      <td>(444.5, 416.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-01</th>\n",
       "      <td>(456.5, 458.5)</td>\n",
       "      <td>(456.5, 463.0)</td>\n",
       "      <td>(456.5, 471.5)</td>\n",
       "      <td>(449.5, 445.0)</td>\n",
       "      <td>(449.5, 443.0)</td>\n",
       "      <td>(449.5, 431.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-02</th>\n",
       "      <td>(460.0, 461.5)</td>\n",
       "      <td>(460.0, 465.0)</td>\n",
       "      <td>(460.0, 471.5)</td>\n",
       "      <td>(455.0, 451.5)</td>\n",
       "      <td>(455.0, 449.5)</td>\n",
       "      <td>(455.0, 441.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-03</th>\n",
       "      <td>(450.0, 455.0)</td>\n",
       "      <td>(450.0, 457.5)</td>\n",
       "      <td>(450.0, 470.0)</td>\n",
       "      <td>(443.0, 440.5)</td>\n",
       "      <td>(443.0, 435.5)</td>\n",
       "      <td>(443.0, 426.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-04</th>\n",
       "      <td>(453.0, 457.5)</td>\n",
       "      <td>(453.0, 462.0)</td>\n",
       "      <td>(453.0, 475.5)</td>\n",
       "      <td>(444.0, 439.5)</td>\n",
       "      <td>(444.0, 435.5)</td>\n",
       "      <td>(444.0, 421.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-13</th>\n",
       "      <td>(497.5, 500.5)</td>\n",
       "      <td>(497.5, 503.5)</td>\n",
       "      <td>(497.5, 513.0)</td>\n",
       "      <td>(491.0, 487.5)</td>\n",
       "      <td>(491.0, 484.5)</td>\n",
       "      <td>(491.0, 475.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-14</th>\n",
       "      <td>(501.0, 502.5)</td>\n",
       "      <td>(501.0, 505.5)</td>\n",
       "      <td>(501.0, 511.5)</td>\n",
       "      <td>(496.0, 493.0)</td>\n",
       "      <td>(496.0, 491.5)</td>\n",
       "      <td>(496.0, 483.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-15</th>\n",
       "      <td>(503.5, 504.5)</td>\n",
       "      <td>(503.5, 507.0)</td>\n",
       "      <td>(503.5, 511.5)</td>\n",
       "      <td>(500.5, 498.0)</td>\n",
       "      <td>(500.5, 497.0)</td>\n",
       "      <td>(500.5, 491.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-16</th>\n",
       "      <td>(501.5, 504.5)</td>\n",
       "      <td>(501.5, 505.5)</td>\n",
       "      <td>(501.5, 512.5)</td>\n",
       "      <td>(497.5, 496.0)</td>\n",
       "      <td>(497.5, 493.5)</td>\n",
       "      <td>(497.5, 488.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-20</th>\n",
       "      <td>(498.5, 500.5)</td>\n",
       "      <td>(498.5, 502.5)</td>\n",
       "      <td>(498.5, 508.5)</td>\n",
       "      <td>(495.0, 492.5)</td>\n",
       "      <td>(495.0, 491.0)</td>\n",
       "      <td>(495.0, 484.5)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           R1-R2 Put Spread R1-R3 Put Spread R1-R4 Put Spread  \\\n",
       "Date                                                            \n",
       "2022-01-31   (455.0, 458.0)   (455.0, 465.5)   (455.0, 479.0)   \n",
       "2022-02-01   (456.5, 458.5)   (456.5, 463.0)   (456.5, 471.5)   \n",
       "2022-02-02   (460.0, 461.5)   (460.0, 465.0)   (460.0, 471.5)   \n",
       "2022-02-03   (450.0, 455.0)   (450.0, 457.5)   (450.0, 470.0)   \n",
       "2022-02-04   (453.0, 457.5)   (453.0, 462.0)   (453.0, 475.5)   \n",
       "...                     ...              ...              ...   \n",
       "2024-02-13   (497.5, 500.5)   (497.5, 503.5)   (497.5, 513.0)   \n",
       "2024-02-14   (501.0, 502.5)   (501.0, 505.5)   (501.0, 511.5)   \n",
       "2024-02-15   (503.5, 504.5)   (503.5, 507.0)   (503.5, 511.5)   \n",
       "2024-02-16   (501.5, 504.5)   (501.5, 505.5)   (501.5, 512.5)   \n",
       "2024-02-20   (498.5, 500.5)   (498.5, 502.5)   (498.5, 508.5)   \n",
       "\n",
       "           S1-S2 Call Spread S1-S3 Call Spread S1-S4 Call Spread  \n",
       "Date                                                              \n",
       "2022-01-31    (444.5, 437.0)    (444.5, 434.0)    (444.5, 416.0)  \n",
       "2022-02-01    (449.5, 445.0)    (449.5, 443.0)    (449.5, 431.5)  \n",
       "2022-02-02    (455.0, 451.5)    (455.0, 449.5)    (455.0, 441.5)  \n",
       "2022-02-03    (443.0, 440.5)    (443.0, 435.5)    (443.0, 426.0)  \n",
       "2022-02-04    (444.0, 439.5)    (444.0, 435.5)    (444.0, 421.5)  \n",
       "...                      ...               ...               ...  \n",
       "2024-02-13    (491.0, 487.5)    (491.0, 484.5)    (491.0, 475.0)  \n",
       "2024-02-14    (496.0, 493.0)    (496.0, 491.5)    (496.0, 483.5)  \n",
       "2024-02-15    (500.5, 498.0)    (500.5, 497.0)    (500.5, 491.0)  \n",
       "2024-02-16    (497.5, 496.0)    (497.5, 493.5)    (497.5, 488.0)  \n",
       "2024-02-20    (495.0, 492.5)    (495.0, 491.0)    (495.0, 484.5)  \n",
       "\n",
       "[516 rows x 6 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def round_to_nearest_50_cents(value):\n",
    "    \"\"\"Round the value to the nearest 50 cents.\"\"\"\n",
    "    return np.round(value * 2, 0) / 2\n",
    "\n",
    "def generate_credit_spreads(data):\n",
    "    # Initialize a list to hold the spreads for each day\n",
    "    spreads = []\n",
    "    \n",
    "    # Iterate through each row in the DataFrame\n",
    "    for index, row in data.iterrows():\n",
    "        # Initialize a dictionary for the current day's spreads\n",
    "        day_spreads = {\n",
    "            'Date': index,\n",
    "            'R1-R2 Put Spread': None,\n",
    "            'R1-R3 Put Spread': None,\n",
    "            'R1-R4 Put Spread': None,\n",
    "            'S1-S2 Call Spread': None,\n",
    "            'S1-S3 Call Spread': None,\n",
    "            'S1-S4 Call Spread': None,\n",
    "        }\n",
    "        \n",
    "        # Calculate the put credit spreads for each pair of resistances\n",
    "        for i in range(2, 5):\n",
    "            sell_strike = round_to_nearest_50_cents(row['R1'])\n",
    "            buy_strike = round_to_nearest_50_cents(row[f'R{i}'])\n",
    "            day_spreads[f'R1-R{i} Put Spread'] = (sell_strike, buy_strike)\n",
    "        \n",
    "        # Calculate the call credit spreads for each pair of supports\n",
    "        for i in range(2, 5):\n",
    "            sell_strike = round_to_nearest_50_cents(row['S1'])\n",
    "            buy_strike = round_to_nearest_50_cents(row[f'S{i}'])\n",
    "            day_spreads[f'S1-S{i} Call Spread'] = (sell_strike, buy_strike)\n",
    "        \n",
    "        # Add the current day's spreads to the list\n",
    "        spreads.append(day_spreads)\n",
    "    \n",
    "    # Convert the list of spreads into a DataFrame for easier viewing\n",
    "    spreads_df = pd.DataFrame(spreads)\n",
    "    spreads_df.set_index('Date', inplace=True)\n",
    "    return spreads_df\n",
    "\n",
    "# Assuming spy_data is already defined and contains the necessary columns\n",
    "# Generate the credit spreads\n",
    "credit_spreads = generate_credit_spreads(spy_data)\n",
    "print(credit_spreads)\n",
    "credit_spreads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b97d8e-bc6d-45b6-84a4-ff5aeb2e6db8",
   "metadata": {},
   "source": [
    "# Probability of a Credit Spread expiring worthless\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bdeb04-a017-42de-b430-c688c400acb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d03e88b-a651-41d2-b8d4-da9a81a86aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
