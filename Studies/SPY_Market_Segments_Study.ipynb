{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1abb26ff",
   "metadata": {},
   "source": [
    "## 1. Data Collection & Technical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79ffb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yfinance alpha_vantage pandas_datareader requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5de8465",
   "metadata": {},
   "source": [
    "### 1.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e024dabd",
   "metadata": {},
   "source": [
    "- Brief overview of the study objective.\n",
    "- Importance of analyzing SPY across different market segments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a2f6a7",
   "metadata": {},
   "source": [
    "### 1.2 Data Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4a7269",
   "metadata": {},
   "source": [
    "- Description of data sources (e.g., Yahoo Finance, Alpha Vantage).\n",
    "- Justification for choosing these sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a69ad697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from mplfinance.original_flavor import candlestick_ohlc\n",
    "import seaborn as sns\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3b89dc",
   "metadata": {},
   "source": [
    "### 1.3 Data Collection Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f28aca",
   "metadata": {},
   "source": [
    "- Python code to fetch hourly time series data for SPY.\n",
    "- Include pre-market, market hours, and extended hours data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cad0bb5",
   "metadata": {},
   "source": [
    "### 1.4 Initial Data Exploration\n",
    "Apparently Yahoo doesnt get extended hours data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b668b59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "spy_hourly_data = yf.download('SPY', period='60d', interval='1h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "479c72e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use alpha_vantage data\n",
    "def fetch_hourly_data(symbol, api_key):\n",
    "    # Set up the API parameters\n",
    "    params = {\n",
    "        'function': 'TIME_SERIES_INTRADAY',\n",
    "        'symbol': symbol,\n",
    "        'interval': '60min',\n",
    "        'apikey': api_key,\n",
    "        'outputsize': 'full'\n",
    "    }\n",
    "    \n",
    "    # Make the request to Alpha Vantage API\n",
    "    response = requests.get(\"https://www.alphavantage.co/query\", params=params)\n",
    "    response.raise_for_status()  # Raise an exception for HTTP error codes\n",
    "    \n",
    "    # Parse the JSON response\n",
    "    data = response.json()\n",
    "    # The data is usually under the \"Time Series (60min)\" key, but this might change\n",
    "    # Please check the exact structure of the response JSON\n",
    "    time_series_key = list(data.keys())[1]\n",
    "    hourly_data = data[time_series_key]\n",
    "    \n",
    "    # Convert to a Pandas DataFrame\n",
    "    df = pd.DataFrame.from_dict(hourly_data, orient='index', dtype=float)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df = df.rename(columns={\n",
    "        '1. open': 'Open',\n",
    "        '2. high': 'High',\n",
    "        '3. low': 'Low',\n",
    "        '4. close': 'Close',\n",
    "        '5. volume': 'Volume'\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Use the function with your API key\n",
    "api_key = 'ZKVJP2N2JKBY2WPZ'  # Replace with your actual API key\n",
    "\n",
    "\n",
    "spy_hourly_alpha_data = fetch_hourly_data('SPY', api_key)\n",
    "# Make copies of the data to split into different market segments\n",
    "pre_market_alpha_data = spy_hourly_alpha_data.between_time('04:00:00', market_start).copy()\n",
    "market_hours_alpha_data = spy_hourly_alpha_data.between_time(market_start, market_end).copy()\n",
    "extended_hours_alpha_data = spy_hourly_alpha_data.between_time(market_end, '20:00:00').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8a2184",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spy_hourly_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b57b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spy_hourly_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d198e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spy_hourly_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e850fbb3",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Splitting Market Segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e58978",
   "metadata": {},
   "source": [
    "### 2.1 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec6237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define market hours for the NYSE\n",
    "# market_start = '09:30:00'\n",
    "# market_end = '16:00:00'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2f286a",
   "metadata": {},
   "source": [
    "### 2.2 Segmenting Market Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6d3cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copies of the data to split into different market segments\n",
    "pre_market_data = spy_hourly_data.between_time('04:00:00', market_start).copy()\n",
    "market_hours_data = spy_hourly_data.between_time(market_start, market_end).copy()\n",
    "extended_hours_data = spy_hourly_data.between_time(market_end, '20:00:00').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b820900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of each segment\n",
    "print(\"Pre-Market Data:\")\n",
    "print(pre_market_alpha_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07647025",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMarket Hours Data:\")\n",
    "print(market_hours_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03a75bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nExtended Hours Data:\")\n",
    "print(extended_hours_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b486f82b",
   "metadata": {},
   "source": [
    "### 2.3 Ensuring Consistency & Data Quality'\n",
    "This section is design to help double check data quality before visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "27ce0350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data contains missing values.\n"
     ]
    }
   ],
   "source": [
    "# Check and Validate Pre-Market Data\n",
    "def check_pre_market_data_quality(data):\n",
    "    # Check for missing values\n",
    "    if data.isnull().values.any():\n",
    "        print(\"Data contains missing values.\")\n",
    "        # Optionally, handle missing values by filling or dropping\n",
    "        # data = data.dropna() or data = data.fillna(method='ffill')\n",
    "        \n",
    "    # Check for duplicate timestamps\n",
    "    if data.index.duplicated().any():\n",
    "        print(\"Data contains duplicate timestamps.\")\n",
    "        # Optionally, drop duplicates\n",
    "        # data = data[~data.index.duplicated(keep='first')]\n",
    "    \n",
    "    # Check for large jumps in price\n",
    "    data['returns'] = data['Close'].pct_change()\n",
    "    if data['returns'].abs().max() > 0.03:  # Arbitrary threshold for significant return\n",
    "        print(\"Data contains large price jumps.\")\n",
    "        # Optionally, inspect large jumps\n",
    "        # large_jumps = data[data['returns'].abs() > 0.03]\n",
    "        \n",
    "    # Check if close is ever less than low or more than high\n",
    "    if ((data['Close'] < data['Low']) | (data['Close'] > data['High'])).any():\n",
    "        print(\"Data contains Close price outside of Low/High range.\")\n",
    "    \n",
    "    # More checks can be added as per the data characteristics and requirements\n",
    "    \n",
    "    # Return the data with a new column 'returns' if no issues, or with issues handled if needed\n",
    "#     return data\n",
    "\n",
    "checked_pre_market_data = check_pre_market_data_quality(pre_market_data)\n",
    "checked_pre_market_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7b0f994b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_market_data_quality(df):\n",
    "    \"\"\"\n",
    "    Enhanced function to check for common data issues in market hours stock data and return errors.\n",
    "    :param df: DataFrame with stock data\n",
    "    :return: Prints error messages and counts for each type of error found. If no errors, prints \"no errors found\".\n",
    "    \"\"\"\n",
    "    \n",
    "    errors = []\n",
    "    error_counts = {\n",
    "        'missing_values': 0,\n",
    "        'duplicate_timestamps': 0,\n",
    "        'large_price_jumps': 0,\n",
    "        'large_price_drops': 0\n",
    "    }\n",
    "    \n",
    "    # Ensure data only includes hours in which options can be traded (assumed to be regular market hours for this example)\n",
    "    market_start, market_end = '09:30:00', '16:00:00'\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df = df.between_time(market_start, market_end)\n",
    "\n",
    "    # Check for missing or blank values\n",
    "    if df.isnull().values.any():\n",
    "        errors.append(\"Data contains missing values.\")\n",
    "        error_counts['missing_values'] = df.isnull().sum().sum()\n",
    "\n",
    "    # Check for duplicate indices (timestamps)\n",
    "    if df.index.duplicated().any():\n",
    "        errors.append(\"Data contains duplicate timestamps.\")\n",
    "        error_counts['duplicate_timestamps'] = df.index.duplicated().sum()\n",
    "\n",
    "    # Check for large price jumps or drops (> 3%)\n",
    "    df['Price_Change'] = df['Close'].pct_change()\n",
    "    jumps = df[df['Price_Change'] > 0.03]\n",
    "    drops = df[df['Price_Change'] < -0.03]\n",
    "    \n",
    "    if not jumps.empty:\n",
    "        errors.append(\"Data contains large price jumps (> 3%).\")\n",
    "        error_counts['large_price_jumps'] = len(jumps)\n",
    "        \n",
    "    if not drops.empty:\n",
    "        errors.append(\"Data contains large price drops (> 3%).\")\n",
    "        error_counts['large_price_drops'] = len(drops)\n",
    "\n",
    "    # Print errors and counts\n",
    "    if errors:\n",
    "        for error in errors:\n",
    "            print(error)\n",
    "        for error_type, count in error_counts.items():\n",
    "            if count > 0: print(f\"{error_type}: {count}\")\n",
    "    else:\n",
    "        print(\"No errors found.\")\n",
    "    \n",
    "    return None  # Function modified to not return the DataFrame, but could be adjusted to return error details if needed\n",
    "\n",
    "# Assuming 'market_hours_data' is a DataFrame loaded with relevant market hours data\n",
    "# Example usage would be as follows (commented out since 'market_hours_data' is not defined in this cell):\n",
    "check_market_data_quality(market_hours_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2b334080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data includes times outside expected post-market hours.\n",
      "Data contains missing values.\n"
     ]
    }
   ],
   "source": [
    "# POST MARKET / EXTENDED HOUR DATA\n",
    "import pandas as pd\n",
    "\n",
    "def check_post_market_data_quality(data, market_end='16:00:00'):\n",
    "    \"\"\"\n",
    "    Check for common data issues in post-market stock data.\n",
    "    \n",
    "    :param data: DataFrame with stock data assumed to be post-market.\n",
    "    :param market_end: String representing the market closing time to verify against.\n",
    "    :return: DataFrame after performing checks and flagging rows with issues.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert index to datetime if it's not already\n",
    "    if not pd.api.types.is_datetime64_any_dtype(data.index):\n",
    "        data.index = pd.to_datetime(data.index)\n",
    "\n",
    "    # Check if data is outside market hours (after market_end)\n",
    "    if not data.between_time(market_end, '23:59:59').empty:\n",
    "        print(\"Data includes times outside expected post-market hours.\")\n",
    "\n",
    "    # Check for missing values\n",
    "    if data.isnull().any().any():\n",
    "        print(\"Data contains missing values.\")\n",
    "        # Optional: Handle missing values here\n",
    "\n",
    "    # Check for duplicate indices\n",
    "    if data.index.duplicated().any():\n",
    "        print(\"Data contains duplicate indices.\")\n",
    "        # Optional: Handle duplicates here\n",
    "\n",
    "    # Check for large price swings that may indicate bad ticks or outliers\n",
    "    data['Price_Change'] = data['Close'].pct_change()\n",
    "    if (data['Price_Change'].abs() > 0.05).any():  # Threshold at 5%\n",
    "        print(\"Data contains large price changes, possible outliers.\")\n",
    "\n",
    "    # More checks can be added based on the specific use case...\n",
    "\n",
    "    # Return data with quality checks performed\n",
    "#     return data\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have a DataFrame 'post_market_data' with post-market data\n",
    "checked_post_market_data = check_post_market_data_quality(extended_hours_alpha_data)\n",
    "checked_post_market_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a902e836",
   "metadata": {},
   "source": [
    "## 3. Data Visualization of Market Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176d0304",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Insert Python code here for data visualization of market segments\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from mplfinance.original_flavor import candlestick_ohlc\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_candlestick_interactive(df, title):\n",
    "    # Filter out the data based on the condition\n",
    "    increasing_df = df[df['Close'] > df['Open'] * 1.03]\n",
    "    decreasing_df = df[df['Close'] < df['Open'] * 0.97]\n",
    "    neutral_df = df[(df['Close'] <= df['Open'] * 1.03) & (df['Close'] >= df['Open'] * 0.97)]\n",
    "\n",
    "    # Create figure and add candlestick trace\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Neutral candles\n",
    "    fig.add_trace(go.Candlestick(x=neutral_df.index, open=neutral_df['Open'], high=neutral_df['High'],\n",
    "                                 low=neutral_df['Low'], close=neutral_df['Close'], \n",
    "                                 increasing_line_color='green', decreasing_line_color='red',\n",
    "                                 name='Neutral'))\n",
    "    \n",
    "    # Increasing candles\n",
    "    fig.add_trace(go.Candlestick(x=increasing_df.index, open=increasing_df['Open'], high=increasing_df['High'],\n",
    "                                 low=increasing_df['Low'], close=increasing_df['Close'],\n",
    "                                 increasing_line_color='black', decreasing_line_color='black',\n",
    "                                 name='Increase > 3%'))\n",
    "    \n",
    "    # Decreasing candles\n",
    "    fig.add_trace(go.Candlestick(x=decreasing_df.index, open=decreasing_df['Open'], high=decreasing_df['High'],\n",
    "                                 low=decreasing_df['Low'], close=decreasing_df['Close'],\n",
    "                                 increasing_line_color='white', decreasing_line_color='white',\n",
    "                                 name='Decrease > 3%'))\n",
    "\n",
    "    # Update the layout\n",
    "    fig.update_layout(title=title, xaxis_title='Date', yaxis_title='Price', xaxis_rangeslider_visible=False)\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "# Example usage with your dataframe:\n",
    "# plot_candlestick_interactive(spy_hourly_data, 'SPY Hourly Data Candlestick Chart')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6e1edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and Validate Post-Market Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ffbf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function with each DataFrame\n",
    "plot_candlestick_interactive(spy_hourly_data, 'SPY Hourly Data Candlestick Chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cce9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_candlestick_interactive(pre_market_alpha_data, 'SPY Pre-Market Data Candlestick Chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db511483",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_candlestick_interactive(market_hours_data, 'SPY Market Hours Data Candlestick Chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff27bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_candlestick_interactive(extended_hours_alpha_data, 'SPY Extended Hours Data Candlestick Chart')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7d4897",
   "metadata": {},
   "source": [
    "### 3.1 Overview of Visualization Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b5e833",
   "metadata": {},
   "source": [
    "- Introduction to visualization libraries (e.g., Matplotlib, Seaborn)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4501c3ee",
   "metadata": {},
   "source": [
    "### 3.2 Comparative Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497202cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Python code here for comparative visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc959048",
   "metadata": {},
   "source": [
    "### 3.3 Trends and Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6149f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Python code here to identify trends and patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6f292d",
   "metadata": {},
   "source": [
    "## 4. Forecasting OHLC & Visualizing Tomorrow's Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993d1681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Python code here for forecasting OHLC and visualizing tomorrow's forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f9809a",
   "metadata": {},
   "source": [
    "### 4.1 Forecasting Models Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464f70ec",
   "metadata": {},
   "source": [
    "- Introduction to forecasting models (e.g., ARIMA, LSTM)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5695c23b",
   "metadata": {},
   "source": [
    "### 4.2 Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd03217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Python code here for model implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f74e905",
   "metadata": {},
   "source": [
    "### 4.3 Visualization of Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5460481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Python code here for visualization of forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42b4cff",
   "metadata": {},
   "source": [
    "## 5. Backtesting NightShare Strategy (Sell Premarket, Buy Post-market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2df2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Python code here for backtesting NightShare strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c230a048",
   "metadata": {},
   "source": [
    "### 5.1 Strategy Rationale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c94539",
   "metadata": {},
   "source": [
    "- Explanation of the NightShare strategy.\n",
    "- Hypothesis on why it might be effective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e2e31f",
   "metadata": {},
   "source": [
    "### 5.2 Backtesting Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f644335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Python code here for the backtesting framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560319b2",
   "metadata": {},
   "source": [
    "### 5.3 Strategy Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0a9e11b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Python code here for strategy performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92422b6",
   "metadata": {},
   "source": [
    "## 6. Conclusions: Practical Business Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f32daf7",
   "metadata": {},
   "source": [
    "### 6.1 Key Findings\n",
    "- Summary of significant insights from each section.\n",
    "\n",
    "### 6.2 Practical Implications\n",
    "- How investors/traders can use this study.\n",
    "- Limitations and considerations for real-world application.\n",
    "\n",
    "### 6.3 Future Research Directions\n",
    "- Suggestions for further studies or improvements.\n",
    "- Potential for algorithmic trading strategies based on findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bdcb93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de37ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9429f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebafde4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6f73c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7003cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2854945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3363563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3e66f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
