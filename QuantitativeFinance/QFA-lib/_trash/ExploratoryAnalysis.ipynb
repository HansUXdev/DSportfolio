{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all the libraries and frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from pandas_datareader import data as pdr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy as si\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error\n",
    "import concurrent.futures\n",
    "import backtrader as bt\n",
    "import quandl\n",
    "import QuantLib as ql\n",
    "import quantstats as qs\n",
    "from datetime import datetime\n",
    "\n",
    "from data_collection.data_forecasting import *\n",
    "from data_collection.data_seasonality import *\n",
    "from data_collection.data_visualization import *\n",
    "\n",
    "# # Import custom functions\n",
    "# from data_collection.data_processing    import (\n",
    "#     load_data, load_price_data, \n",
    "#     half_kelly_criterion, calculate_half_kelly_fractions, position_size_half_kelly,\n",
    "#     # calculate_returns, \n",
    "#     create_summary_csv, analyze_ticker,\n",
    "#     bollinger_bands, macd, rsi, woodie_pivots, atr, stochastic_oscillator,\n",
    "#     # create_seasonality_table, resample_to_monthly, fetch_fundamentals,\n",
    "#     # half_kelly_criterion, calculate_half_kelly_fractions, position_size_half_kelly, \n",
    "#     # backtest_strategy_with_half_kelly, get_fundamentals_data\n",
    "# )\n",
    "# # from data_collection.data_processing import calculate_returns\n",
    "\n",
    "# # def calculate_returns(df):\n",
    "# #     \"\"\"Calculate the daily returns.\"\"\"\n",
    "# #     df['Return'] = df['Adj Close'].pct_change() * 100\n",
    "# #     return df\n",
    "\n",
    "# from data_collection.data_visualization import (\n",
    "#     plot_technical_indicators, plot_monthly_technical_indicators, plot_with_macro_data, \n",
    "#     plot_spreads, plot_ghost_candles, plot_cumulative_returns_with_half_kelly\n",
    "# )\n",
    "\n",
    "\n",
    "# from data_collection.data_forecasting import (\n",
    "#     forecast_and_plot, download_stock_data, forecast_future, scale_data, create_sequences, build_and_train_model,\n",
    "#     calculate_metrics, plot_forecasts,plot_ghost_candles, machine_learning_analysis, get_fundamental_ratios, arima_forecast, garch_forecast, backtest_strategy\n",
    "# )\n",
    "\n",
    "# from data_collection.data_seasonality import (\n",
    "#     create_seasonality_table\n",
    "# )\n",
    "\n",
    "# from seasonality_analysis import (\n",
    "#     seasonality_analysis, display_seasonality_stats, display_all_monthly_statistics,\n",
    "#     visualize_seasonality_table\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\jupyter-ai\\Lib\\site-packages\\yfinance\\utils.py:775: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
      "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2010-01-04    7.622500    7.660714    7.585000    7.643214    6.461977   \n",
      "2010-01-05    7.664286    7.699643    7.616071    7.656429    6.473150   \n",
      "2010-01-06    7.656429    7.686786    7.526786    7.534643    6.370186   \n",
      "2010-01-07    7.562500    7.571429    7.466071    7.520714    6.358409   \n",
      "2010-01-08    7.510714    7.571429    7.466429    7.570714    6.400682   \n",
      "...                ...         ...         ...         ...         ...   \n",
      "2020-12-24  131.320007  133.460007  131.100006  131.970001  129.339020   \n",
      "2020-12-28  133.990005  137.339996  133.509995  136.690002  133.964920   \n",
      "2020-12-29  138.050003  138.789993  134.339996  134.869995  132.181198   \n",
      "2020-12-30  135.580002  135.990005  133.399994  133.720001  131.054138   \n",
      "2020-12-31  134.080002  134.740005  131.720001  132.690002  130.044647   \n",
      "\n",
      "               Volume    Return  \n",
      "Date                             \n",
      "2010-01-04  493729600       NaN  \n",
      "2010-01-05  601904800  0.172900  \n",
      "2010-01-06  552160000 -1.590631  \n",
      "2010-01-07  477131200 -0.184876  \n",
      "2010-01-08  447610800  0.664837  \n",
      "...               ...       ...  \n",
      "2020-12-24   54930100  0.771195  \n",
      "2020-12-28  124486200  3.576570  \n",
      "2020-12-29  121047300 -1.331484  \n",
      "2020-12-30   96452100 -0.852663  \n",
      "2020-12-31   99116600 -0.770285  \n",
      "\n",
      "[2769 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_returns(df):\n",
    "    \"\"\"Calculate the daily returns.\"\"\"\n",
    "    df['Return'] = df['Adj Close'].pct_change() * 100\n",
    "    return df\n",
    "\n",
    "data = load_price_data('AAPL', '2010-01-01', '2021-01-01')\n",
    "\n",
    "# Calculate the returns\n",
    "returns = calculate_returns(data)\n",
    "print(returns)\n",
    "# daily_technical = get_daily_woodies_pivots_with_bollinger(data, 20, 2, 2)\n",
    "# print(daily_technical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default figure size\n",
    "plt.rcParams['figure.figsize'] = (8, 6)  # Change these values to your desired size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\jupyter-ai\\Lib\\site-packages\\yfinance\\utils.py:775: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
      "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'arima_forecast' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[39m# # Create summary CSV\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[39m# create_summary_csv(tickers, start_date, end_date)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 13\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[34], line 7\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m end_date \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m2024-01-01\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m ticker \u001b[39min\u001b[39;00m tickers:\n\u001b[1;32m----> 7\u001b[0m     analyze_ticker(ticker, start_date, end_date)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\Desktop\\DataSciencePortfolio\\QuantitativeFinance\\Studies\\Seasonality\\data_collection\\data_processing.py:149\u001b[0m, in \u001b[0;36manalyze_ticker\u001b[1;34m(ticker, start_date, end_date)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    148\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mReturn\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mAdj Close\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mpct_change() \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m--> 149\u001b[0m df \u001b[39m=\u001b[39m ichimoku_cloud(df)\n\u001b[0;32m    150\u001b[0m df \u001b[39m=\u001b[39m add_technical_indicators(df)\n\u001b[0;32m    152\u001b[0m \u001b[39m# ARIMA and GARCH Forecasts\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'arima_forecast' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    tickers = ['SPY', 'QQQ', 'TQQQ', 'SQQQ', 'SOXL', 'TSLL', 'NVDL']\n",
    "    start_date = '2000-01-01'\n",
    "    end_date = '2024-01-01'\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        analyze_ticker(ticker, start_date, end_date)\n",
    "    \n",
    "    # # Create summary CSV\n",
    "    # create_summary_csv(tickers, start_date, end_date)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of Results and Interpretation for Each Asset in the Notebook\n",
    "\n",
    "The notebook includes analysis for multiple assets, specifically SPY, QQQ, TQQQ, SQQQ, SOXL, TSLL, and NVDL. Each function follows a similar pattern:\n",
    "1. Load price data.\n",
    "2. Calculate returns.\n",
    "3. Create a seasonality table.\n",
    "4. Visualize the seasonality table.\n",
    "5. Display monthly statistics.\n",
    "\n",
    "#### General Approach:\n",
    "1. **Load Price Data**:\n",
    "   - Using `yfinance` to load adjusted closing prices for the specified period.\n",
    "2. **Calculate Returns**:\n",
    "   - Daily returns are calculated as the percentage change in adjusted closing prices.\n",
    "3. **Create Seasonality Table**:\n",
    "   - Monthly returns are calculated and aggregated to show mean, standard deviation, count of observations, and the probability of positive returns.\n",
    "4. **Visualize Seasonality Table**:\n",
    "   - A heatmap is used to visualize the seasonality statistics.\n",
    "5. **Display Monthly Statistics**:\n",
    "   - Monthly mean returns and other statistics are printed.\n",
    "\n",
    "#### Metrics Explained:\n",
    "- **Mean Monthly Return**: This is the average return for a particular month across all years in the dataset. A positive mean indicates that the asset generally performs well in that month, while a negative mean suggests poorer performance.\n",
    "- **Standard Deviation (std)**: This measures the volatility of returns for a particular month. A higher standard deviation indicates more variability and hence higher risk.\n",
    "- **Count**: This is the number of observations or data points available for that particular month. A higher count improves the reliability of the mean and standard deviation.\n",
    "- **Positive Probability**: This is the probability that the returns for a given month are positive. It is calculated as the proportion of months with positive returns to the total number of months. A higher positive probability suggests more consistent positive performance in that month.\n",
    "\n",
    "### SPY (S&P 500 ETF)\n",
    "- **Mean Monthly Return**: Generally positive, with notable highs in April (2.0%) and November (2.4%).\n",
    "- **Standard Deviation**: Moderate volatility, with the highest standard deviation in October (5.8%).\n",
    "- **Positive Probability**: High probability of positive returns in April and November (75%).\n",
    "\n",
    "### QQQ (Nasdaq-100 ETF)\n",
    "- **Mean Monthly Return**: Positive overall, with high returns in November (2.9%) and January (0.92%).\n",
    "- **Standard Deviation**: High volatility in February (8.1%) and October (8.0%).\n",
    "- **Positive Probability**: Higher probability of positive returns in May (75%) and November (62%).\n",
    "\n",
    "### TQQQ (Triple-Leveraged QQQ ETF)\n",
    "- **Mean Monthly Return**: Extremely high in some months, e.g., July (10.9%) and April (11.8%).\n",
    "- **Standard Deviation**: Extremely high volatility, particularly in February (24.9%) and November (18.1%).\n",
    "- **Positive Probability**: High probability of positive returns in April (67%) and July (62%).\n",
    "\n",
    "### SQQQ (Triple-Leveraged Inverse QQQ ETF)\n",
    "- **Mean Monthly Return**: Negative in most months, reflecting the inverse nature of the ETF. Highest negative return in July (-13%).\n",
    "- **Standard Deviation**: Volatile, especially in November (9.8%) and January (17%).\n",
    "- **Positive Probability**: Low probability of positive returns, with 50% probability in June and August being the highest.\n",
    "\n",
    "### SOXL (Triple-Leveraged Semiconductor ETF)\n",
    "- **Mean Monthly Return**: High returns in certain months, e.g., November (7.0%) and January (4.9%).\n",
    "- **Standard Deviation**: High volatility, particularly in March (26.7%) and November (16.2%).\n",
    "- **Positive Probability**: High probability of positive returns in October (62%) and November (67%).\n",
    "\n",
    "### TSLL (Triple-Leveraged Tesla ETF)\n",
    "- **Mean Monthly Return**: Volatile, with high returns in May (11.5%) and November (8.6%).\n",
    "- **Standard Deviation**: Extremely high volatility in February (40.2%) and October (27.6%).\n",
    "- **Positive Probability**: High probability of positive returns in May (64%) and November (67%).\n",
    "\n",
    "### NVDL (Triple-Leveraged Nvidia ETF)\n",
    "- **Mean Monthly Return**: Volatile, with high returns in April (10.8%) and November (8.7%).\n",
    "- **Standard Deviation**: High volatility, especially in March (24.5%) and November (26.8%).\n",
    "- **Positive Probability**: High probability of positive returns in April (67%) and November (62%).\n",
    "\n",
    "### Interpretation:\n",
    "1. **Seasonality Trends**:\n",
    "   - Some ETFs exhibit clear seasonality patterns, such as higher returns in certain months.\n",
    "   - Leveraged ETFs (e.g., TQQQ, SOXL, TSLL) show extreme returns and volatility, emphasizing the high risk-reward nature.\n",
    "2. **Investment Strategy**:\n",
    "   - Investors could use this seasonality information to time entries and exits.\n",
    "   - For instance, historically strong months might be preferred for initiating long positions.\n",
    "3. **Risk Management**:\n",
    "   - Higher standard deviations indicate periods of higher risk, necessitating careful risk management.\n",
    "   - Leveraged and inverse ETFs, due to their high volatility, should be approached with caution.\n",
    "\n",
    "### Position Sizing and Risk Management Methods:\n",
    "#### Kelly Criterion:\n",
    "The Kelly Criterion is a formula used to determine the optimal size of a series of bets to maximize the logarithm of wealth. It balances risk and reward by considering the probability of winning and the payoff.\n",
    "\n",
    "\\[ f^* = \\frac{bp - q}{b} \\]\n",
    "\n",
    "Where:\n",
    "- \\( f^* \\) is the fraction of the portfolio to bet.\n",
    "- \\( b \\) is the odds received on the bet.\n",
    "- \\( p \\) is the probability of winning.\n",
    "- \\( q \\) is the probability of losing, which is \\( 1 - p \\).\n",
    "\n",
    "#### Fixed Ratio Method:\n",
    "This method involves increasing position size based on the amount of profit accumulated. It's commonly used in futures and options trading.\n",
    "\n",
    "1. Determine the base position size.\n",
    "2. Increase the position size by a fixed amount after reaching a certain profit threshold.\n",
    "\n",
    "#### Fixed Fractional Method:\n",
    "This method involves risking a fixed percentage of the portfolio on each trade. It's simple and helps in preserving capital.\n",
    "\n",
    "1. Decide the percentage of the portfolio to risk (e.g., 2%).\n",
    "2. Calculate the dollar risk per trade based on the stop loss.\n",
    "\n",
    "#### Managing Margin:\n",
    "Managing margin involves maintaining enough funds in your account to cover the margin requirements for leveraged positions. This can prevent margin calls and forced liquidation.\n",
    "\n",
    "- **Initial Margin**: The amount required to open a position.\n",
    "- **Maintenance Margin**: The minimum amount that must be maintained in the account.\n",
    "\n",
    "#### Hedging:\n",
    "Hedging involves taking an offsetting position in a related security to mitigate risk. Common hedging strategies include using options and futures.\n",
    "\n",
    "- **Options**: Buying puts to protect against downside risk.\n",
    "- **Futures**: Shorting futures contracts to hedge against a potential decline in the asset's price.\n",
    "\n",
    "#### Technical Analysis:\n",
    "Technical analysis involves using historical price data and technical indicators to forecast future price movements. Common tools include:\n",
    "\n",
    "- **Moving Averages**: Used to smooth out price data to identify trends.\n",
    "- **Relative Strength Index (RSI)**: Measures the speed and change of price movements.\n",
    "- **Bollinger Bands**: Provides a relative definition of high and low prices.\n",
    "\n",
    "#### Fundamental Analysis:\n",
    "Fundamental analysis involves evaluating an asset's intrinsic value based on economic and financial factors. Key elements include:\n",
    "\n",
    "- **Earnings Reports**: Assessing a company's profitability.\n",
    "- **Economic Indicators**: Analyzing GDP growth, unemployment rates, etc.\n",
    "- **Valuation Ratios**: Using P/E ratio, P/B ratio, etc., to determine if an asset is overvalued or undervalued.\n",
    "\n",
    "By understanding these trends and applying appropriate position sizing and risk management strategies, investors can make more informed decisions, potentially leveraging seasonal patterns to optimize returns and manage risks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    tickers = ['SPY', 'QQQ', 'TQQQ', 'SQQQ', 'SOXL', 'TSLL', 'NVDL']\n",
    "    start_date = '2000-01-01'\n",
    "    end_date = '2024-01-01'\n",
    "    \n",
    "    # for ticker in tickers:\n",
    "    #     analyze_ticker(ticker, start_date, end_date)\n",
    "\n",
    "    # Create summary CSV\n",
    "    create_summary_csv(tickers, start_date, end_date)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main():\n",
    "    tickers = ['SPY', 'QQQ', 'TQQQ', 'SQQQ', 'SOXL', 'TSLL', 'NVDL']\n",
    "    start_date = '2000-01-01'\n",
    "    end_date = '2024-01-01'\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        analyze_ticker(ticker, start_date, end_date)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import custom functions\n",
    "from data_collection.data_processing    import (\n",
    "    load_data, load_price_data, \n",
    "    analyze_ticker,\n",
    "    half_kelly_criterion, calculate_half_kelly_fractions, position_size_half_kelly,\n",
    "    # calculate_return\n",
    "    # create_seasonality_table, resample_to_monthly, fetch_fundamentals,\n",
    "    bollinger_bands, macd, rsi, woodie_pivots, atr, stochastic_oscillator,\n",
    "    # half_kelly_criterion, calculate_half_kelly_fractions, position_size_half_kelly, \n",
    "    # backtest_strategy_with_half_kelly, get_fundamentals_data\n",
    ")\n",
    "# from data_collection.data_processing import calculate_returns\n",
    "\n",
    "# ]\n",
    "# from data_collection.data_visualization import (\n",
    "#     plot_technical_indicators, plot_monthly_technical_indicators, plot_with_macro_data, \n",
    "#     plot_spreads, plot_ghost_candles, plot_cumulative_returns_with_half_kelly\n",
    "# )\n",
    "\n",
    "\n",
    "# from data_collection.data_forecasting import (\n",
    "#     forecast_and_plot, download_stock_data, forecast_future, scale_data, create_sequences, build_and_train_model,\n",
    "#     calculate_metrics, plot_forecasts,plot_ghost_candles, machine_learning_analysis, get_fundamental_ratios, arima_forecast, garch_forecast, backtest_strategy\n",
    "# )\n",
    "\n",
    "# from seasonality_analysis import (\n",
    "#     seasonality_analysis, display_seasonality_stats, display_all_monthly_statistics,\n",
    "#     visualize_seasonality_table\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default figure size\n",
    "plt.rcParams['figure.figsize'] = (8, 6)  # Change these values to your desired size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\jupyter-ai\\Lib\\site-packages\\yfinance\\utils.py:775: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
      "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'arima_forecast' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[39m# # Create summary CSV\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[39m# create_summary_csv(tickers, start_date, end_date)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 13\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[35], line 7\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m end_date \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m2024-01-01\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m ticker \u001b[39min\u001b[39;00m tickers:\n\u001b[1;32m----> 7\u001b[0m     analyze_ticker(ticker, start_date, end_date)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\Desktop\\DataSciencePortfolio\\QuantitativeFinance\\Studies\\Seasonality\\data_collection\\data_processing.py:149\u001b[0m, in \u001b[0;36manalyze_ticker\u001b[1;34m(ticker, start_date, end_date)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    148\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mReturn\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mAdj Close\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mpct_change() \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m--> 149\u001b[0m df \u001b[39m=\u001b[39m ichimoku_cloud(df)\n\u001b[0;32m    150\u001b[0m df \u001b[39m=\u001b[39m add_technical_indicators(df)\n\u001b[0;32m    152\u001b[0m \u001b[39m# ARIMA and GARCH Forecasts\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'arima_forecast' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    tickers = ['SPY', 'QQQ', 'TQQQ', 'SQQQ', 'SOXL', 'TSLL', 'NVDL']\n",
    "    start_date = '2000-01-01'\n",
    "    end_date = '2024-01-01'\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        analyze_ticker(ticker, start_date, end_date)\n",
    "    \n",
    "    # # Create summary CSV\n",
    "    # create_summary_csv(tickers, start_date, end_date)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of Results and Interpretation for Each Asset in the Notebook\n",
    "\n",
    "The notebook includes analysis for multiple assets, specifically SPY, QQQ, TQQQ, SQQQ, SOXL, TSLL, and NVDL. Each function follows a similar pattern:\n",
    "1. Load price data.\n",
    "2. Calculate returns.\n",
    "3. Create a seasonality table.\n",
    "4. Visualize the seasonality table.\n",
    "5. Display monthly statistics.\n",
    "\n",
    "#### General Approach:\n",
    "1. **Load Price Data**:\n",
    "   - Using `yfinance` to load adjusted closing prices for the specified period.\n",
    "2. **Calculate Returns**:\n",
    "   - Daily returns are calculated as the percentage change in adjusted closing prices.\n",
    "3. **Create Seasonality Table**:\n",
    "   - Monthly returns are calculated and aggregated to show mean, standard deviation, count of observations, and the probability of positive returns.\n",
    "4. **Visualize Seasonality Table**:\n",
    "   - A heatmap is used to visualize the seasonality statistics.\n",
    "5. **Display Monthly Statistics**:\n",
    "   - Monthly mean returns and other statistics are printed.\n",
    "\n",
    "#### Metrics Explained:\n",
    "- **Mean Monthly Return**: This is the average return for a particular month across all years in the dataset. A positive mean indicates that the asset generally performs well in that month, while a negative mean suggests poorer performance.\n",
    "- **Standard Deviation (std)**: This measures the volatility of returns for a particular month. A higher standard deviation indicates more variability and hence higher risk.\n",
    "- **Count**: This is the number of observations or data points available for that particular month. A higher count improves the reliability of the mean and standard deviation.\n",
    "- **Positive Probability**: This is the probability that the returns for a given month are positive. It is calculated as the proportion of months with positive returns to the total number of months. A higher positive probability suggests more consistent positive performance in that month.\n",
    "\n",
    "### SPY (S&P 500 ETF)\n",
    "- **Mean Monthly Return**: Generally positive, with notable highs in April (2.0%) and November (2.4%).\n",
    "- **Standard Deviation**: Moderate volatility, with the highest standard deviation in October (5.8%).\n",
    "- **Positive Probability**: High probability of positive returns in April and November (75%).\n",
    "\n",
    "### QQQ (Nasdaq-100 ETF)\n",
    "- **Mean Monthly Return**: Positive overall, with high returns in November (2.9%) and January (0.92%).\n",
    "- **Standard Deviation**: High volatility in February (8.1%) and October (8.0%).\n",
    "- **Positive Probability**: Higher probability of positive returns in May (75%) and November (62%).\n",
    "\n",
    "### TQQQ (Triple-Leveraged QQQ ETF)\n",
    "- **Mean Monthly Return**: Extremely high in some months, e.g., July (10.9%) and April (11.8%).\n",
    "- **Standard Deviation**: Extremely high volatility, particularly in February (24.9%) and November (18.1%).\n",
    "- **Positive Probability**: High probability of positive returns in April (67%) and July (62%).\n",
    "\n",
    "### SQQQ (Triple-Leveraged Inverse QQQ ETF)\n",
    "- **Mean Monthly Return**: Negative in most months, reflecting the inverse nature of the ETF. Highest negative return in July (-13%).\n",
    "- **Standard Deviation**: Volatile, especially in November (9.8%) and January (17%).\n",
    "- **Positive Probability**: Low probability of positive returns, with 50% probability in June and August being the highest.\n",
    "\n",
    "### SOXL (Triple-Leveraged Semiconductor ETF)\n",
    "- **Mean Monthly Return**: High returns in certain months, e.g., November (7.0%) and January (4.9%).\n",
    "- **Standard Deviation**: High volatility, particularly in March (26.7%) and November (16.2%).\n",
    "- **Positive Probability**: High probability of positive returns in October (62%) and November (67%).\n",
    "\n",
    "### TSLL (Triple-Leveraged Tesla ETF)\n",
    "- **Mean Monthly Return**: Volatile, with high returns in May (11.5%) and November (8.6%).\n",
    "- **Standard Deviation**: Extremely high volatility in February (40.2%) and October (27.6%).\n",
    "- **Positive Probability**: High probability of positive returns in May (64%) and November (67%).\n",
    "\n",
    "### NVDL (Triple-Leveraged Nvidia ETF)\n",
    "- **Mean Monthly Return**: Volatile, with high returns in April (10.8%) and November (8.7%).\n",
    "- **Standard Deviation**: High volatility, especially in March (24.5%) and November (26.8%).\n",
    "- **Positive Probability**: High probability of positive returns in April (67%) and November (62%).\n",
    "\n",
    "### Interpretation:\n",
    "1. **Seasonality Trends**:\n",
    "   - Some ETFs exhibit clear seasonality patterns, such as higher returns in certain months.\n",
    "   - Leveraged ETFs (e.g., TQQQ, SOXL, TSLL) show extreme returns and volatility, emphasizing the high risk-reward nature.\n",
    "2. **Investment Strategy**:\n",
    "   - Investors could use this seasonality information to time entries and exits.\n",
    "   - For instance, historically strong months might be preferred for initiating long positions.\n",
    "3. **Risk Management**:\n",
    "   - Higher standard deviations indicate periods of higher risk, necessitating careful risk management.\n",
    "   - Leveraged and inverse ETFs, due to their high volatility, should be approached with caution.\n",
    "\n",
    "### Position Sizing and Risk Management Methods:\n",
    "#### Kelly Criterion:\n",
    "The Kelly Criterion is a formula used to determine the optimal size of a series of bets to maximize the logarithm of wealth. It balances risk and reward by considering the probability of winning and the payoff.\n",
    "\n",
    "\\[ f^* = \\frac{bp - q}{b} \\]\n",
    "\n",
    "Where:\n",
    "- \\( f^* \\) is the fraction of the portfolio to bet.\n",
    "- \\( b \\) is the odds received on the bet.\n",
    "- \\( p \\) is the probability of winning.\n",
    "- \\( q \\) is the probability of losing, which is \\( 1 - p \\).\n",
    "\n",
    "#### Fixed Ratio Method:\n",
    "This method involves increasing position size based on the amount of profit accumulated. It's commonly used in futures and options trading.\n",
    "\n",
    "1. Determine the base position size.\n",
    "2. Increase the position size by a fixed amount after reaching a certain profit threshold.\n",
    "\n",
    "#### Fixed Fractional Method:\n",
    "This method involves risking a fixed percentage of the portfolio on each trade. It's simple and helps in preserving capital.\n",
    "\n",
    "1. Decide the percentage of the portfolio to risk (e.g., 2%).\n",
    "2. Calculate the dollar risk per trade based on the stop loss.\n",
    "\n",
    "#### Managing Margin:\n",
    "Managing margin involves maintaining enough funds in your account to cover the margin requirements for leveraged positions. This can prevent margin calls and forced liquidation.\n",
    "\n",
    "- **Initial Margin**: The amount required to open a position.\n",
    "- **Maintenance Margin**: The minimum amount that must be maintained in the account.\n",
    "\n",
    "#### Hedging:\n",
    "Hedging involves taking an offsetting position in a related security to mitigate risk. Common hedging strategies include using options and futures.\n",
    "\n",
    "- **Options**: Buying puts to protect against downside risk.\n",
    "- **Futures**: Shorting futures contracts to hedge against a potential decline in the asset's price.\n",
    "\n",
    "#### Technical Analysis:\n",
    "Technical analysis involves using historical price data and technical indicators to forecast future price movements. Common tools include:\n",
    "\n",
    "- **Moving Averages**: Used to smooth out price data to identify trends.\n",
    "- **Relative Strength Index (RSI)**: Measures the speed and change of price movements.\n",
    "- **Bollinger Bands**: Provides a relative definition of high and low prices.\n",
    "\n",
    "#### Fundamental Analysis:\n",
    "Fundamental analysis involves evaluating an asset's intrinsic value based on economic and financial factors. Key elements include:\n",
    "\n",
    "- **Earnings Reports**: Assessing a company's profitability.\n",
    "- **Economic Indicators**: Analyzing GDP growth, unemployment rates, etc.\n",
    "- **Valuation Ratios**: Using P/E ratio, P/B ratio, etc., to determine if an asset is overvalued or undervalued.\n",
    "\n",
    "By understanding these trends and applying appropriate position sizing and risk management strategies, investors can make more informed decisions, potentially leveraging seasonal patterns to optimize returns and manage risks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    tickers = ['SPY', 'QQQ', 'TQQQ', 'SQQQ', 'SOXL', 'TSLL', 'NVDL']\n",
    "    start_date = '2000-01-01'\n",
    "    end_date = '2024-01-01'\n",
    "    \n",
    "    # for ticker in tickers:\n",
    "    #     analyze_ticker(ticker, start_date, end_date)\n",
    "\n",
    "    # Create summary CSV\n",
    "    create_summary_csv(tickers, start_date, end_date)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yfinance as yf\n",
    "# import yoptions as yo\n",
    "# import optionlab as ol\n",
    "# import pandas as pd\n",
    "# from pandas_datareader import data as pdr\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import numpy as np\n",
    "# import scipy as si\n",
    "# from scipy import stats\n",
    "# from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "# from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# import concurrent.futures\n",
    "# import backtrader as bt\n",
    "# import quandl\n",
    "# import QuantLib as ql\n",
    "# import quantstats as qs\n",
    "\n",
    "# # Import custom functions\n",
    "# from data_collection.load_data import load_price_data\n",
    "# from data_collection.resample_data import resample_to_monthly\n",
    "# from data_collection.technicals import bollinger_bands, macd, rsi, woodie_pivots, obv, atr, stochastic_oscillator\n",
    "\n",
    "# # Import functions from the provided files\n",
    "# from analysis.seasonality_analysis import seasonality_analysis, display_seasonality_stats, plot_seasonality\n",
    "\n",
    "# # Set default figure size\n",
    "# plt.rcParams['figure.figsize'] = (8, 6)\n",
    "\n",
    "# Technical Indicators\n",
    "def ichimoku_cloud(df):\n",
    "    if 'High' not in df.columns or 'Low' not in df.columns:\n",
    "        print(\"Data does not contain 'High' or 'Low' columns necessary for Ichimoku Cloud.\")\n",
    "        return df\n",
    "\n",
    "    high_9 = df['High'].rolling(window=9).max()\n",
    "    low_9 = df['Low'].rolling(window=9).min()\n",
    "    df['tenkan_sen'] = (high_9 + low_9) / 2\n",
    "\n",
    "    high_26 = df['High'].rolling(window=26).max()\n",
    "    low_26 = df['Low'].rolling(window=26).min()\n",
    "    df['kijun_sen'] = (high_26 + low_26) / 2\n",
    "\n",
    "    df['senkou_span_a'] = ((df['tenkan_sen'] + df['kijun_sen']) / 2).shift(26)\n",
    "    high_52 = df['High'].rolling(window=52).max()\n",
    "    low_52 = df['Low'].rolling(window=52).min()\n",
    "    df['senkou_span_b'] = ((high_52 + low_52) / 2).shift(26)\n",
    "\n",
    "    df['chikou_span'] = df['Adj Close'].shift(-26)\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_technical_indicators(df):\n",
    "    try:\n",
    "        df = bollinger_bands(df)\n",
    "        df = macd(df)\n",
    "        df = rsi(df)\n",
    "        df = woodie_pivots(df)\n",
    "        df = obv(df)\n",
    "        df = atr(df)\n",
    "        df = stochastic_oscillator(df)\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing column for technical indicator calculation: {e}\")\n",
    "    return df\n",
    "\n",
    "# Advanced Statistical Models\n",
    "def arima_forecast(df, column='Adj Close', order=(5, 1, 0)):\n",
    "    model = ARIMA(df[column], order=order)\n",
    "    model_fit = model.fit()\n",
    "    forecast = model_fit.forecast(steps=10)\n",
    "    return forecast\n",
    "\n",
    "def garch_forecast(df, column='Adj Close'):\n",
    "    model = arch_model(df[column], vol='Garch', p=1, q=1)\n",
    "    model_fit = model.fit()\n",
    "    forecast = model_fit.forecast(horizon=10)\n",
    "    return forecast\n",
    "\n",
    "# Fundamental Analysis\n",
    "def get_fundamental_ratios(ticker):\n",
    "    stock = yf.Ticker(ticker)\n",
    "    pe_ratio = stock.info.get('trailingPE', None)\n",
    "    pb_ratio = stock.info.get('priceToBook', None)\n",
    "    debt_to_equity = stock.info.get('debtToEquity', None)\n",
    "    return pe_ratio, pb_ratio, debt_to_equity\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "def optimize_model_hyperparameters(X, y):\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Backtesting Framework\n",
    "class MyStrategy(bt.Strategy):\n",
    "    params = (\n",
    "        ('maperiod', 15),\n",
    "    )\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dataclose = self.datas[0].close\n",
    "        self.order = None\n",
    "        self.sma = bt.indicators.SimpleMovingAverage(self.datas[0], period=self.params.maperiod)\n",
    "\n",
    "    def next(self):\n",
    "        if self.order:\n",
    "            return\n",
    "\n",
    "        if not self.position:\n",
    "            if self.dataclose[0] > self.sma[0]:\n",
    "                self.order = self.buy()\n",
    "        else:\n",
    "            if self.dataclose[0] < self.sma[0]:\n",
    "                self.order = self.sell()\n",
    "\n",
    "def backtest_strategy(df):\n",
    "    cerebro = bt.Cerebro()\n",
    "    cerebro.addstrategy(MyStrategy)\n",
    "    data = bt.feeds.PandasData(dataname=df)\n",
    "    cerebro.adddata(data)\n",
    "    cerebro.run()\n",
    "    cerebro.plot()\n",
    "\n",
    "# Main Analysis Function\n",
    "def analyze_ticker(ticker, start_date, end_date):\n",
    "    df = load_price_data(ticker, start=start_date, end=end_date)\n",
    "    \n",
    "    if isinstance(df, pd.Series):\n",
    "        df = df.to_frame(name='Adj Close')\n",
    "    \n",
    "    if 'Adj Close' not in df.columns:\n",
    "        print(f\"Column 'Adj Close' not found in the data for {ticker}. Available columns: {df.columns}\")\n",
    "        return\n",
    "    \n",
    "    if 'Close' not in df.columns or 'High' not in df.columns or 'Low' not in df.columns:\n",
    "        print(f\"Columns 'Close', 'High', and 'Low' are required. Available columns: {df.columns}\")\n",
    "        return\n",
    "    \n",
    "    df['Return'] = df['Adj Close'].pct_change() * 100\n",
    "    df = ichimoku_cloud(df)\n",
    "    df = add_technical_indicators(df)\n",
    "\n",
    "    # ARIMA and GARCH Forecasts\n",
    "    arima_forecast(df)\n",
    "    garch_forecast(df)\n",
    "\n",
    "    # Fundamental Ratios\n",
    "    pe_ratio, pb_ratio, debt_to_equity = get_fundamental_ratios(ticker)\n",
    "    print(f\"P/E Ratio: {pe_ratio}, P/B Ratio: {pb_ratio}, Debt to Equity: {debt_to_equity}\")\n",
    "\n",
    "    # Machine Learning with Hyperparameter Optimization\n",
    "    df['Target'] = (df['Return'] > 0).astype(int)\n",
    "    features = ['Adj Close', 'Return']\n",
    "    X = df[features].shift(1).dropna()\n",
    "    y = df['Target'].shift(1).dropna()\n",
    "    X, y = X.align(y, join='inner')\n",
    "    best_model = optimize_model_hyperparameters(X, y)\n",
    "    y_pred = best_model.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    print(f\"Optimized Model Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    # Backtest Strategy\n",
    "    backtest_strategy(df)\n",
    "\n",
    "def main():\n",
    "    tickers = ['SPY', 'QQQ', 'TQQQ', 'SQQQ', 'SOXL', 'TSLL', 'NVDL']\n",
    "    start_date = '2000-01-01'\n",
    "    end_date = '2024-01-01'\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        analyze_ticker(ticker, start_date, end_date)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom functions\n",
    "from data_collection.data_processing import load_price_data, fetch_financial_data, load_data\n",
    "from data_collection.data_processing import resample_to_monthly\n",
    "from data_collection.data_processing import bollinger_bands, macd, rsi, woodie_pivots, atr, stochastic_oscillator, ichimoku_cloud"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Analysis of Seasonalitlity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions from the provided files\n",
    "from analysis.seasonality_analysis import seasonality_analysis, display_seasonality_stats, plot_seasonality, create_seasonality_table, display_all_monthly_statistics\n",
    "\n",
    "# Import functions from the provided files\n",
    "from analysis.seasonality_analysis import seasonality_analysis, display_seasonality_stats, plot_seasonality, create_seasonality_table, display_all_monthly_statistics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Forecasting with ARIMA, SARIMA, and SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from QuantitativeFinance.Studies.Seasonality.data_collection.data_forecasting import forecast_and_plot_complete, forecast_and_plot\n",
    "# forecast_and_plot_with_confidence_intervals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a CSV of historical technical data from a given asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning, Feature Imporance and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create summary CSV\n",
    "# tickers = ['SPY', 'QQQ', 'TQQQ', 'SQQQ', 'SOXL', 'TSLL', 'NVDL']\n",
    "# start_date = '2000-01-01'\n",
    "# end_date = '2024-01-01'\n",
    "# create_summary_csv(tickers, start_date, end_date)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the initial seasonality of each asset ('SPY', 'QQQ', 'TQQQ', 'SQQQ', 'SOXL', 'TSLL', 'NVDL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    tickers = ['SPY', 'QQQ', 'TQQQ', 'SQQQ', 'SOXL', 'TSLL', 'NVDL']\n",
    "    start_date = '2000-01-01'\n",
    "    end_date = '2024-01-01'\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        analyze_ticker(ticker, start_date, end_date)\n",
    "    \n",
    "    # # Create summary CSV\n",
    "    # create_summary_csv(tickers, start_date, end_date)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
